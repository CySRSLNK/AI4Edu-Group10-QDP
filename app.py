# -*- coding:utf-8 -*-
import streamlit as st
import torch
import pandas as pd
from datetime import datetime

from models.layers import SimpleTARNN
from utils import data_helper as dh

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="é¢˜ç›®éš¾åº¦é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ“š",
    layout="wide"
)

# æ ‡é¢˜
st.title("ğŸ“š é¢˜ç›®éš¾åº¦é¢„æµ‹ç³»ç»Ÿ")
st.markdown("ä½¿ç”¨ SimpleTARNN æ¨¡å‹é¢„æµ‹é¢˜ç›®çš„éš¾åº¦ç­‰çº§")

# ä¾§è¾¹æ 
st.sidebar.header("æ¨¡å‹é…ç½®")

# åˆå§‹åŒ–å†å²é¢„æµ‹è®°å½•
if 'history' not in st.session_state:
    st.session_state['history'] = []

# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_model_and_tokenizer(model_path="saved_models/final_model.pt"):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œåˆ†è¯å™¨"""
    try:
        # åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
        checkpoint = torch.load(model_path, map_location='cuda',weights_only=False)
        args = checkpoint['args']
        
        # åŠ è½½åˆ†è¯å™¨
        if args.bert_mod == 'local':
            tokenizer = dh.load_bert_tokenizer(local_path=args.bert_path)
        else:
            tokenizer = dh.load_bert_tokenizer(model_name=args.bert_name)
        
        # åˆå§‹åŒ–æ¨¡å‹
        vocab_size = tokenizer.vocab_size
        model = SimpleTARNN(
            args=args,
            vocab_size=vocab_size,
            num_classes=args.num_classes,
            bert_hidden_size=768
        )
        
        # åŠ è½½æ¨¡å‹æƒé‡
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        # è·å–éš¾åº¦æ˜ å°„
        difficulty_map = dh.get_diff_map()
        reverse_diff_map = {v: k for k, v in difficulty_map.items()}
        
        return model, tokenizer, args, reverse_diff_map
        
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
        return None, None, None, None

# éš¾åº¦ç­‰çº§æè¿°
DIFFICULTY_DESCRIPTION = {
    "å®¹æ˜“": "åŸºç¡€é¢˜ç›®ï¼Œé€‚åˆåˆå­¦è€…",
    "è¾ƒæ˜“": "ç®€å•é¢˜ç›®ï¼Œéœ€è¦åŸºæœ¬ç†è§£",
    "ä¸€èˆ¬": "ä¸­ç­‰éš¾åº¦é¢˜ç›®ï¼Œéœ€è¦æŒæ¡æ ¸å¿ƒæ¦‚å¿µ",
    "è¾ƒéš¾": "è¾ƒéš¾é¢˜ç›®ï¼Œéœ€è¦ç»¼åˆåº”ç”¨çŸ¥è¯†",
    "å›°éš¾": "é«˜éš¾åº¦é¢˜ç›®ï¼Œéœ€è¦æ·±åº¦æ€è€ƒå’Œå¤æ‚æ¨ç†"
}

def predict_difficulty(model, tokenizer, text, args, max_length=256):
    """é¢„æµ‹é¢˜ç›®éš¾åº¦"""
    # ç¼–ç æ–‡æœ¬
    encoded = tokenizer.encode_plus(
        text,
        truncation=True,
        padding='max_length',
        max_length=max_length,
        return_tensors='pt'
    )
    
    # è·å–è¾“å…¥
    input_ids = encoded['input_ids']
    attention_mask = encoded['attention_mask']
    token_type_ids = encoded.get('token_type_ids', torch.zeros_like(input_ids))
    
    # é¢„æµ‹
    with torch.no_grad():
        logits, scores = model(input_ids, attention_mask, token_type_ids)
        probabilities = torch.softmax(logits, dim=1)
        prediction = torch.argmax(scores, dim=1).item()
        confidence = probabilities[0][prediction].item()
    
    return prediction, confidence, probabilities[0].tolist()

def add_to_history(question_content, prediction, confidence, reverse_diff_map, probabilities):
    """å°†é¢„æµ‹ç»“æœæ·»åŠ åˆ°å†å²è®°å½•"""
    difficulty_level = reverse_diff_map.get(prediction, "æœªçŸ¥")
    
    history_entry = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "question_content": question_content[:100] + "..." if len(question_content) > 100 else question_content,
        "full_content": question_content,
        "predicted_difficulty": difficulty_level,
        "confidence": confidence,
        "prediction_value": prediction,
        "probabilities": probabilities
    }
    
    st.session_state['history'].insert(0, history_entry)  # æ·»åŠ åˆ°å¼€å¤´
    
    # ä¿æŒå†å²è®°å½•æœ€å¤š100æ¡
    if len(st.session_state['history']) > 100:
        st.session_state['history'] = st.session_state['history'][:100]
    
    return history_entry

def clear_history():
    """æ¸…ç©ºå†å²è®°å½•"""
    st.session_state['history'] = []

def main():
    # æ¨¡å‹é€‰æ‹©
    model_option = st.sidebar.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        ["é»˜è®¤æ¨¡å‹", "è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„"]
    )
    
    if model_option == "è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„":
        model_path = st.sidebar.text_input("æ¨¡å‹æ–‡ä»¶è·¯å¾„", "saved_models/final_model.pt")
    else:
        model_path = "saved_models/final_model.pt"
    
    # åŠ è½½æ¨¡å‹
    if st.sidebar.button("åŠ è½½æ¨¡å‹", type="primary"):
        with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
            model, tokenizer, args, reverse_diff_map = load_model_and_tokenizer(model_path)
            
            if model:
                st.session_state['model'] = model
                st.session_state['tokenizer'] = tokenizer
                st.session_state['args'] = args
                st.session_state['reverse_diff_map'] = reverse_diff_map
                st.sidebar.success("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
    if 'model' not in st.session_state:
        st.warning("è¯·å…ˆåŠ è½½æ¨¡å‹")
        return
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["ğŸ“ å•é¢˜é¢„æµ‹", "ğŸ“Š å†å²é¢„æµ‹", "â„¹ï¸ æ¨¡å‹ä¿¡æ¯"])
    
    # æ ‡ç­¾é¡µ1: å•é¢˜é¢„æµ‹
    with tab1:
        st.header("å•é¢˜éš¾åº¦é¢„æµ‹")
        
        col1, col2 = st.columns([3,2])
        
        with col1:
            # è¾“å…¥åŒºåŸŸ
            question_content = st.text_area(
                "é¢˜ç›®å†…å®¹",
                height=200,
                placeholder="è¯·è¾“å…¥é¢˜ç›®å†…å®¹...",
                help="è¾“å…¥å®Œæ•´çš„é¢˜ç›®å†…å®¹è¿›è¡Œéš¾åº¦é¢„æµ‹"
            )
             
        # é¢„æµ‹æŒ‰é’®
        if st.button("é¢„æµ‹éš¾åº¦", type="primary"):
            if not question_content.strip():
                st.error("è¯·è¾“å…¥é¢˜ç›®å†…å®¹ï¼")
            else:
                with st.spinner("æ­£åœ¨é¢„æµ‹..."):
                    # è¿›è¡Œé¢„æµ‹
                    prediction, confidence, probabilities = predict_difficulty(
                        st.session_state['model'],
                        st.session_state['tokenizer'],
                        question_content,
                        st.session_state['args']
                    )
                    
                    # æ·»åŠ åˆ°å†å²è®°å½•
                    history_entry = add_to_history(
                        question_content,
                        prediction,
                        confidence,
                        st.session_state['reverse_diff_map'],
                        probabilities
                    )
                    
                    # æ˜¾ç¤ºç»“æœ
                    difficulty_level = history_entry['predicted_difficulty']
                    
                    st.success(f"é¢„æµ‹å®Œæˆï¼å·²æ·»åŠ åˆ°å†å²è®°å½•")
                    
                    # ç»“æœæ˜¾ç¤º
                    result_col1, result_col2 = st.columns(2)
                    
                    with result_col1:
                        st.metric(
                            label="ğŸ“Š é¢„æµ‹éš¾åº¦",
                            value=difficulty_level,
                            delta=f"ç½®ä¿¡åº¦: {confidence:.2%}"
                        )
                        
                        # æ˜¾ç¤ºæ¯ä¸ªç­‰çº§çš„æ¦‚ç‡
                        st.markdown("### å„ç­‰çº§æ¦‚ç‡åˆ†å¸ƒ")
                        for i in range(5):
                            level_name = st.session_state['reverse_diff_map'].get(i, f"ç­‰çº§{i}")
                            prob = probabilities[i]
                            
                            # è¿›åº¦æ¡æ˜¾ç¤ºæ¦‚ç‡
                            col_prob1, col_prob2 = st.columns([3, 1])
                            with col_prob1:
                                st.progress(prob, text=f"{level_name}")
                            with col_prob2:
                                st.write(f"{prob:.2%}")
                    
                    with result_col2:
                        # éš¾åº¦æè¿°
                        st.markdown("### ğŸ“– éš¾åº¦æè¿°")
                        st.info(DIFFICULTY_DESCRIPTION.get(difficulty_level, "æœªçŸ¥éš¾åº¦ç­‰çº§"))
                        
                        # é¢„æµ‹è¯¦æƒ…
                        with st.expander("ğŸ“‹ é¢„æµ‹è¯¦æƒ…"):
                            st.write(f"**é¢„æµ‹æ—¶é—´:** {history_entry['timestamp']}")
                            st.write(f"**éš¾åº¦æ•°å€¼:** {prediction}")
                            st.write(f"**ç½®ä¿¡åº¦:** {confidence:.2%}")
                            st.write(f"**å®Œæ•´æ¦‚ç‡åˆ†å¸ƒ:**")
                            
                            prob_df = pd.DataFrame({
                                'éš¾åº¦ç­‰çº§': [st.session_state['reverse_diff_map'].get(i, f"ç­‰çº§{i}") for i in range(5)],
                                'æ¦‚ç‡': [f"{p:.2%}" for p in probabilities],
                                'æ•°å€¼': probabilities
                            })
                            st.dataframe(prob_df, use_container_width=True, hide_index=True)
    
    # æ ‡ç­¾é¡µ2: å†å²é¢„æµ‹
    with tab2:
        st.header("å†å²é¢„æµ‹è®°å½•")
        
        if not st.session_state['history']:
            st.info("æš‚æ— å†å²é¢„æµ‹è®°å½•ï¼Œè¯·åœ¨å•é¢˜é¢„æµ‹ä¸­è¿›è¡Œé¢„æµ‹")
        else:
            # å†å²è®°å½•ç»Ÿè®¡
            col_stat1, col_stat2, col_stat3 = st.columns(3)
            
            total_count = len(st.session_state['history'])
            most_common = max(
                [(st.session_state['reverse_diff_map'].get(h['prediction_value'], "æœªçŸ¥"), 
                  sum(1 for h in st.session_state['history'] if h['prediction_value'] == h['prediction_value'])) 
                 for h in st.session_state['history']], 
                key=lambda x: x[1]
            )
            avg_confidence = sum(h['confidence'] for h in st.session_state['history']) / total_count
            
            with col_stat1:
                st.metric("æ€»é¢„æµ‹æ¬¡æ•°", total_count)
            with col_stat2:
                st.metric("æœ€å¸¸è§éš¾åº¦", most_common[0])
            with col_stat3:
                st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.2%}")
            
            # æ¸…ç©ºå†å²æŒ‰é’®
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²è®°å½•", type="secondary"):
                clear_history()
                st.rerun()
            
            # æœç´¢å’Œç­›é€‰åŠŸèƒ½
            st.subheader("ğŸ“‹ å†å²è®°å½•åˆ—è¡¨")
            
            search_col1, search_col2 = st.columns([2, 1])
            with search_col1:
                search_text = st.text_input("æœç´¢é¢˜ç›®å†…å®¹", placeholder="è¾“å…¥å…³é”®è¯æœç´¢...")
            with search_col2:
                difficulty_filter = st.selectbox(
                    "ç­›é€‰éš¾åº¦ç­‰çº§",
                    ["å…¨éƒ¨"] + [st.session_state['reverse_diff_map'].get(i, f"ç­‰çº§{i}") for i in range(5)]
                )
            
            # æ˜¾ç¤ºå†å²è®°å½•è¡¨æ ¼
            filtered_history = st.session_state['history']
            
            if search_text:
                filtered_history = [h for h in filtered_history if search_text.lower() in h['question_content'].lower()]
            
            if difficulty_filter != "å…¨éƒ¨":
                filtered_history = [h for h in filtered_history if h['predicted_difficulty'] == difficulty_filter]
            
            if filtered_history:
                # åˆ›å»ºæ˜¾ç¤ºç”¨çš„DataFrame
                display_data = []
                for i, entry in enumerate(filtered_history):
                    display_data.append({
                        "åºå·": i + 1,
                        "é¢„æµ‹æ—¶é—´": entry['timestamp'],
                        "é¢˜ç›®å†…å®¹": entry['question_content'],
                        "é¢„æµ‹éš¾åº¦": entry['predicted_difficulty'],
                        "ç½®ä¿¡åº¦": f"{entry['confidence']:.2%}",
                        "éš¾åº¦æ•°å€¼": entry['prediction_value'],
                        "å®Œæ•´å†…å®¹": entry['full_content']
                    })
                
                df = pd.DataFrame(display_data)
                
                # åˆ†é¡µæ˜¾ç¤º
                page_size = 10
                total_pages = (len(df) + page_size - 1) // page_size
                
                page_num = st.number_input(
                    f"é¡µç  (å…±{total_pages}é¡µ)", 
                    min_value=1, 
                    max_value=total_pages if total_pages > 0 else 1,
                    value=1
                )
                
                start_idx = (page_num - 1) * page_size
                end_idx = min(start_idx + page_size, len(df))
                
                # æ˜¾ç¤ºå½“å‰é¡µæ•°æ®
                st.dataframe(
                    df.iloc[start_idx:end_idx][["åºå·", "é¢„æµ‹æ—¶é—´", "é¢˜ç›®å†…å®¹", "é¢„æµ‹éš¾åº¦", "ç½®ä¿¡åº¦"]],
                    use_container_width=True,
                    hide_index=True
                )
                
                # æŸ¥çœ‹è¯¦ç»†å†…å®¹
                selected_idx = st.selectbox(
                    "é€‰æ‹©è®°å½•æŸ¥çœ‹è¯¦æƒ…",
                    options=[f"{i+1}. {row['é¢˜ç›®å†…å®¹']}" for i, row in df.iterrows()],
                    index=0
                )
                
                if selected_idx:
                    selected_num = int(selected_idx.split(".")[0]) - 1
                    selected_entry = filtered_history[selected_num]
                    
                    with st.expander("ğŸ“„ æŸ¥çœ‹è¯¦æƒ…", expanded=True):
                        st.write("**å®Œæ•´é¢˜ç›®å†…å®¹:**")
                        st.text_area("", selected_entry['full_content'], height=150, disabled=True)
                        
                        st.write("**é¢„æµ‹ç»“æœ:**")
                        col_detail1, col_detail2 = st.columns(2)
                        with col_detail1:
                            st.write(f"é¢„æµ‹éš¾åº¦: **{selected_entry['predicted_difficulty']}**")
                            st.write(f"ç½®ä¿¡åº¦: **{selected_entry['confidence']:.2%}**")
                        with col_detail2:
                            st.write(f"é¢„æµ‹æ—¶é—´: {selected_entry['timestamp']}")
                            st.write(f"éš¾åº¦æ•°å€¼: {selected_entry['prediction_value']}")
                        
                        # æ¦‚ç‡åˆ†å¸ƒå›¾
                        st.write("**æ¦‚ç‡åˆ†å¸ƒ:**")
                        prob_data = pd.DataFrame({
                            'éš¾åº¦ç­‰çº§': [st.session_state['reverse_diff_map'].get(i, f"ç­‰çº§{i}") for i in range(5)],
                            'æ¦‚ç‡': selected_entry['probabilities']
                        })
                        st.bar_chart(prob_data.set_index('éš¾åº¦ç­‰çº§'))
                
                # å¯¼å‡ºå†å²è®°å½•
                st.subheader("ğŸ“¤ å¯¼å‡ºå†å²è®°å½•")
                export_col1, export_col2 = st.columns([2, 1])
                
                with export_col1:
                    export_format = st.radio("å¯¼å‡ºæ ¼å¼", ["CSV", "JSON"])
                
                with export_col2:
                    if st.button("å¯¼å‡ºæ•°æ®"):
                        export_df = pd.DataFrame([{
                            "é¢„æµ‹æ—¶é—´": h['timestamp'],
                            "é¢˜ç›®å†…å®¹": h['full_content'],
                            "é¢„æµ‹éš¾åº¦": h['predicted_difficulty'],
                            "éš¾åº¦æ•°å€¼": h['prediction_value'],
                            "ç½®ä¿¡åº¦": h['confidence'],
                            "å®¹æ˜“æ¦‚ç‡": h['probabilities'][0],
                            "è¾ƒæ˜“æ¦‚ç‡": h['probabilities'][1],
                            "ä¸€èˆ¬æ¦‚ç‡": h['probabilities'][2],
                            "è¾ƒéš¾æ¦‚ç‡": h['probabilities'][3],
                            "å›°éš¾æ¦‚ç‡": h['probabilities'][4]
                        } for h in filtered_history])
                        
                        if export_format == "CSV":
                            csv = export_df.to_csv(index=False)
                            st.download_button(
                                label="ä¸‹è½½CSVæ–‡ä»¶",
                                data=csv,
                                file_name=f"éš¾åº¦é¢„æµ‹å†å²_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv"
                            )
                        else:
                            json_data = export_df.to_json(orient='records', force_ascii=False)
                            st.download_button(
                                label="ä¸‹è½½JSONæ–‡ä»¶",
                                data=json_data,
                                file_name=f"éš¾åº¦é¢„æµ‹å†å²_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                                mime="application/json"
                            )
            else:
                st.info("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å†å²è®°å½•")
    
    # æ ‡ç­¾é¡µ3: æ¨¡å‹ä¿¡æ¯
    with tab3:
        st.header("æ¨¡å‹ä¿¡æ¯")
        
        if 'args' in st.session_state:
            # æ¨¡å‹é…ç½®ä¿¡æ¯
            st.subheader("ğŸ“Š æ¨¡å‹é…ç½®")
            
            config_data = {
                "æ¨¡å‹åç§°": "SimpleTARNN",
                "BERTæ¨¡å‹": st.session_state['args'].bert_mod,
                "BERTè·¯å¾„/åç§°": st.session_state['args'].bert_path if st.session_state['args'].bert_mod == 'local' else st.session_state['args'].bert_name,
                "RNNå±‚æ•°": st.session_state['args'].rnn_layers,
                "RNNç»´åº¦": st.session_state['args'].rnn_dim,
                "æ³¨æ„åŠ›ç±»å‹": st.session_state['args'].attention_type,
                "åˆ†ç±»ç±»åˆ«æ•°": st.session_state['args'].num_classes,
                "å­¦ä¹ ç‡": st.session_state['args'].learning_rate,
                "æ‰¹æ¬¡å¤§å°": st.session_state['args'].batch_size,
                "Dropoutç‡": st.session_state['args'].dropout_rate
            }
            
            for key, value in config_data.items():
                st.info(f"**{key}:** {value}")
            
            # éš¾åº¦æ˜ å°„
            st.subheader("ğŸ¯ éš¾åº¦ç­‰çº§æ˜ å°„")
            difficulty_map = dh.get_diff_map()
            
            for level, value in difficulty_map.items():
                st.write(f"- **{level}** â†’ æ•°å€¼æ ‡ç­¾: {value}")
        
        # ä½¿ç”¨è¯´æ˜
        st.subheader("ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. **åŠ è½½æ¨¡å‹**: åœ¨ä¾§è¾¹æ ç‚¹å‡»"åŠ è½½æ¨¡å‹"æŒ‰é’®
        2. **å•é¢˜é¢„æµ‹**: åœ¨"å•é¢˜é¢„æµ‹"æ ‡ç­¾é¡µè¾“å…¥é¢˜ç›®å†…å®¹è¿›è¡Œé¢„æµ‹
        3. **å†å²é¢„æµ‹**: åœ¨"å†å²é¢„æµ‹"æ ‡ç­¾é¡µæŸ¥çœ‹å’Œç®¡ç†æ‰€æœ‰é¢„æµ‹è®°å½•
        4. **å†å²è®°å½•åŠŸèƒ½**:
           - è‡ªåŠ¨ä¿å­˜æ¯æ¬¡é¢„æµ‹ç»“æœ
           - æ”¯æŒæœç´¢å’Œç­›é€‰
           - å¯ä»¥å¯¼å‡ºä¸ºCSVæˆ–JSONæ ¼å¼
           - æœ€å¤šä¿å­˜100æ¡è®°å½•
        """)
        
        # æ³¨æ„äº‹é¡¹
        st.subheader("âš ï¸ æ³¨æ„äº‹é¡¹")
        st.warning("""
        - ç¡®ä¿BERTæ¨¡å‹è·¯å¾„æ­£ç¡®
        - é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…éš¾åº¦éœ€ç»“åˆä¸“å®¶åˆ¤æ–­
        - æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®åˆ†å¸ƒä¹‹å¤–çš„é¢˜ç›®ä¸Šå¯èƒ½è¡¨ç°ä¸ä½³
        - å†å²è®°å½•ä»…åœ¨å½“å‰ä¼šè¯ä¸­æœ‰æ•ˆï¼Œåˆ·æ–°é¡µé¢ä¼šæ¸…ç©ºå†å²
        """)

if __name__ == "__main__":
    main()